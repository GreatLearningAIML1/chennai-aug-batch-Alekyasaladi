{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_InternalLab_AIML.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "YJRBuqXhOB7_"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "sb7Epo0VOB58"
      },
      "cell_type": "markdown",
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fHpCNRv1OB5-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tnSsH8sNOB6F",
        "slideshow": {
          "slide_type": "fragment"
        },
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Reset Default graph - Needed only for Jupyter notebook\n",
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DxJDmJqqOB6K",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "### Collect Data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FhllFLyKOB6N",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "B4yQKMiJOB6R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "97a9ffbe-3fb1-4c2f-9cb4-00714f660258"
      },
      "cell_type": "code",
      "source": [
        "##data = pd.read_csv('./prices.csv')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SCUHZIJlcVdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/AI_ML/Resiency6 Lab/prices.csv')\n",
        "##!ls \"/content/drive/My Drive/AI_ML/Resiency6 Lab/prices.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HSq9PO3MdONT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fgkX6SEqOB6W"
      },
      "cell_type": "markdown",
      "source": [
        "### Check all columns in the dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7K8pWsNQOB6X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1acd4068-8ef5-4e9f-8a60-655f8a27d30c"
      },
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['date', 'symbol', 'open', 'close', 'low', 'high', 'volume'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7dU6X7MpOB6c"
      },
      "cell_type": "markdown",
      "source": [
        "### Drop columns `date` and  `symbol`"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lh_6spSKOB6e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.drop('date',axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yTNBgNfMfHWe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data.drop('symbol',axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xlwbUgTwOB6i",
        "outputId": "87d6e27e-50c9-4cae-e68c-8b1364f9ebb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>open</th>\n",
              "      <th>close</th>\n",
              "      <th>low</th>\n",
              "      <th>high</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>123.430000</td>\n",
              "      <td>125.839996</td>\n",
              "      <td>122.309998</td>\n",
              "      <td>126.250000</td>\n",
              "      <td>2163600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>125.239998</td>\n",
              "      <td>119.980003</td>\n",
              "      <td>119.940002</td>\n",
              "      <td>125.540001</td>\n",
              "      <td>2386400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>116.379997</td>\n",
              "      <td>114.949997</td>\n",
              "      <td>114.930000</td>\n",
              "      <td>119.739998</td>\n",
              "      <td>2489500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>115.480003</td>\n",
              "      <td>116.620003</td>\n",
              "      <td>113.500000</td>\n",
              "      <td>117.440002</td>\n",
              "      <td>2006300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117.010002</td>\n",
              "      <td>114.970001</td>\n",
              "      <td>114.089996</td>\n",
              "      <td>117.330002</td>\n",
              "      <td>1408600.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         open       close         low        high     volume\n",
              "0  123.430000  125.839996  122.309998  126.250000  2163600.0\n",
              "1  125.239998  119.980003  119.940002  125.540001  2386400.0\n",
              "2  116.379997  114.949997  114.930000  119.739998  2489500.0\n",
              "3  115.480003  116.620003  113.500000  117.440002  2006300.0\n",
              "4  117.010002  114.970001  114.089996  117.330002  1408600.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3DBv3WWYOB6q"
      },
      "cell_type": "markdown",
      "source": [
        "### Consider only first 1000 rows in the dataset for building feature set and target set"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Z_hG9rGBOB6s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "811607b7-93f1-469c-af6e-6802715a0574"
      },
      "cell_type": "code",
      "source": [
        "data_reduced = data.iloc[0:1000,:]\n",
        "data_reduced.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "M3UaApqYOB6x"
      },
      "cell_type": "markdown",
      "source": [
        "### Divide the data into train and test sets"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2EkKAy7fOB6y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainX,testX= train_test_split(data_reduced,test_size=0.3,random_state=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgCSRHDCjEeT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainY = trainX.pop(\"close\")\n",
        "testY = testX.pop(\"close\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "v6vE4eYCOB62",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "## Building the graph in tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xK0zBd1VOB64",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "1.Define input data placeholders"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JDrYlWTuOB66",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Input features\n",
        "x = tf.placeholder(shape=[None,4],dtype=tf.float32, name='x-input')\n",
        "\n",
        "x_n = tf.layers.batch_normalization(x, training=True)\n",
        "\n",
        "#Actual Prices\n",
        "y_ = tf.placeholder(shape=[None],dtype=tf.float32, name='y-input')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "297_qja4OB7A",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "2.Define Weights and Bias"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L205qPeQOB7B",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W = tf.Variable(tf.zeros(shape=[4,1]), name=\"Weights\")\n",
        "b = tf.Variable(tf.zeros(shape=[1]), name=\"Bias\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HgtWA-UIOB7F",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "3.Prediction"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JveGlx25OB7H",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = tf.add(tf.matmul(x_n,W),b,name='output')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TL1hIwf_OB7M",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "4.Loss (Cost) Function [Mean square error]"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8VSWPiGXOB7P",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = tf.reduce_mean(tf.square(y-y_),name='Loss')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jzG85FUlOB7U",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "5.GradientDescent Optimizer to minimize Loss [GradientDescentOptimizer]"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cj802w-3OB7X",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_op = tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xSypb_u8OB7e",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "## Execute the Graph for 100 epochs and observe the loss"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DVvgj7eQOB7f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Lets start graph Execution\n",
        "sess = tf.Session()\n",
        "\n",
        "# variables need to be initialized before we can use them\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "#how many times data need to be shown to model\n",
        "training_epochs = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9smwOW-1OB7k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f401a7c5-ca0f-4f6b-f035-cfdda57da1a6"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "            \n",
        "    #Calculate train_op and loss\n",
        "    _, train_loss = sess.run([train_op, loss],feed_dict={x:trainX, \n",
        "                                                        y_:trainY})\n",
        "    \n",
        "    if epoch % 10 == 0:\n",
        "        print ('Training loss at step: ', epoch, ' is ', train_loss)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss at step:  0  is  8324.748\n",
            "Training loss at step:  10  is  6848.473\n",
            "Training loss at step:  20  is  5858.9277\n",
            "Training loss at step:  30  is  3883.5466\n",
            "Training loss at step:  40  is  3883.4219\n",
            "Training loss at step:  50  is  3883.4104\n",
            "Training loss at step:  60  is  3883.4028\n",
            "Training loss at step:  70  is  3883.3975\n",
            "Training loss at step:  80  is  3883.394\n",
            "Training loss at step:  90  is  3883.392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9JuLI6bSOB7n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d3e0359-781e-401d-de5c-55fadffd1b4c"
      },
      "cell_type": "code",
      "source": [
        "sess.run(y, feed_dict={x:trainX[0:1]})"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[66.62594]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "e4t49pa6nOk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "913ad32a-675a-4274-90eb-e779c8a7d533"
      },
      "cell_type": "code",
      "source": [
        "testY[0:1]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "249    122.169998\n",
              "Name: close, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "DuHy9o4VnNaZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c71fee23-7af0-496f-9357-fb936e6d1f6a"
      },
      "cell_type": "code",
      "source": [
        "sess.run(y, feed_dict={x:testX[0:1]})"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[66.658165]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DOL2ncA1OB7q"
      },
      "cell_type": "markdown",
      "source": [
        "### Get the shapes and values of W and b\n",
        "\n",
        "Hint: Use sess.run(W) to get W."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZGvtyTeuOB7r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "172d78a5-d13e-435e-ec6b-1257dc941c86"
      },
      "cell_type": "code",
      "source": [
        "sess.run(W)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.42802852],\n",
              "       [-5.0080433 ],\n",
              "       [ 3.822392  ],\n",
              "       [ 0.06650945]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vhDtOv5UOB7x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "437e0364-e95f-4d49-c31d-c856e299ee7e"
      },
      "cell_type": "code",
      "source": [
        "sess.run(b)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([26.736284], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SZqKUEFsOB71"
      },
      "cell_type": "markdown",
      "source": [
        "### Find the Absolute mean square loss difference between training and testing loss."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "97t-grQgOB71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb648b3d-8166-4608-d976-33e53e7d5112"
      },
      "cell_type": "code",
      "source": [
        "train_loss = sess.run(loss,feed_dict={x:trainX, \n",
        "                                         y_:trainY})\n",
        "print(train_loss)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3883.3901\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KjOInjUROB75",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_loss = sess.run(loss,feed_dict={x:testX,y_:testY})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CZUAjZ5oOB78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "824dc3fb-bc24-4ec6-d508-6245f6ccce18"
      },
      "cell_type": "code",
      "source": [
        "print(test_loss)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2280.5984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RBId1-gruP5g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06dfb4b5-efe6-4c5b-b9ac-8d991755760e"
      },
      "cell_type": "code",
      "source": [
        "print(\"Absolute mean square loss difference:\", abs(train_loss - test_loss))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Absolute mean square loss difference: 1602.7917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YJRBuqXhOB7_"
      },
      "cell_type": "markdown",
      "source": [
        "### Linear Classification using Keras"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8GoNTWXAOB8C",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "### Building the simple Neural Network in Keras with one neuron in the dense hidden layer.\n",
        "#### Use Mean square error as loss function and sgd as optimizer"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zpeL5rCTOB8D",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize Sequential Graph (model)\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Normalize input data\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=(4,)))\n",
        "\n",
        "#Add Dense layer for prediction - Keras declares weights and bias automatically\n",
        "model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "#Defining the optimizer\n",
        "\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03,clipnorm=1.)\n",
        "\n",
        "#Compile the model - add Loss and Gradient Descent optimizer\n",
        "model.compile(optimizer=sgd_optimizer, loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Wt-HYFMEOB8G",
        "slideshow": {
          "slide_type": "slide"
        }
      },
      "cell_type": "markdown",
      "source": [
        "### Execute the model"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "66JGJt7GOB8H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ec696802-a323-459a-9207-f2b6a98d1269"
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainX, trainY, epochs=10)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "700/700 [==============================] - 0s 327us/step - loss: 7999.3686\n",
            "Epoch 2/10\n",
            "700/700 [==============================] - 0s 92us/step - loss: 7492.6544\n",
            "Epoch 3/10\n",
            "700/700 [==============================] - 0s 91us/step - loss: 6838.8285\n",
            "Epoch 4/10\n",
            "700/700 [==============================] - 0s 94us/step - loss: 6039.7515\n",
            "Epoch 5/10\n",
            "700/700 [==============================] - 0s 112us/step - loss: 5138.0973\n",
            "Epoch 6/10\n",
            "700/700 [==============================] - 0s 93us/step - loss: 4143.3266\n",
            "Epoch 7/10\n",
            "700/700 [==============================] - 0s 95us/step - loss: 3252.9466\n",
            "Epoch 8/10\n",
            "700/700 [==============================] - 0s 93us/step - loss: 2339.8238\n",
            "Epoch 9/10\n",
            "700/700 [==============================] - 0s 95us/step - loss: 1652.9431\n",
            "Epoch 10/10\n",
            "700/700 [==============================] - 0s 88us/step - loss: 1309.2087\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4df799f7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "y36Lp0plZo_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Classification using Keras "
      ]
    },
    {
      "metadata": {
        "id": "r0rFHi8GZo_d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the given Iris data using pandas (Iris.csv)"
      ]
    },
    {
      "metadata": {
        "id": "vJVgLdq1EWbQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.set_random_seed(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1GjCgwkgZo_e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "iris = pd.read_csv('/content/drive/My Drive/AI_ML/Resiency6 Lab/Iris.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fd9XfEuA5zHv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "iris.drop('Id',axis=1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJbeed22xlU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a3b626ed-4034-49cd-b387-5279309b3be1"
      },
      "cell_type": "code",
      "source": [
        "iris.head()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLengthCm</th>\n",
              "      <th>SepalWidthCm</th>\n",
              "      <th>PetalLengthCm</th>\n",
              "      <th>PetalWidthCm</th>\n",
              "      <th>Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
              "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
              "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
              "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
              "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
              "4            5.0           3.6            1.4           0.2  Iris-setosa"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "xrjZaKBYxr74",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "91a532e8-bac8-4fef-916d-8d2f9d0b56a3"
      },
      "cell_type": "code",
      "source": [
        "iris.Species.unique()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "KFj06DLEZo_g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Splitting the data into feature set and target set"
      ]
    },
    {
      "metadata": {
        "id": "IDcl9RqbZo_i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainX_iris,testX_iris= train_test_split(iris,test_size=0.3,random_state=100)\n",
        "trainY_iris = trainX_iris.pop(\"Species\")\n",
        "testY_iris = testX_iris.pop(\"Species\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gnUsBH5lZo_k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Target set has different categories. So, Label encode them. And convert into one-hot vectors using get_dummies in pandas."
      ]
    },
    {
      "metadata": {
        "id": "FIQMQMvX3PHa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "trainY_iris = pd.get_dummies(trainY_iris,drop_first=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-GD89yI4oqE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "testY_iris = pd.get_dummies(testY_iris,drop_first=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NcTgLAK3Zo_o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Divide the dataset into Training and test (70:30)"
      ]
    },
    {
      "metadata": {
        "id": "xBwBH5yJZo_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8dbc6d9-a356-421f-eb80-7ae2657bb029"
      },
      "cell_type": "code",
      "source": [
        "trainX_iris.shape"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "dd7lNHLS490g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b8e4a86-6b9d-4962-c534-a05adbef4958"
      },
      "cell_type": "code",
      "source": [
        "testX_iris.shape"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "metadata": {
        "id": "VBy54Hys9Yix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "004cf648-f101-44a5-afee-938d9884823a"
      },
      "cell_type": "code",
      "source": [
        "trainY_iris.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "4-nEtwKE9dEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1444
        },
        "outputId": "3e433843-7333-4209-e2d4-ba987b433767"
      },
      "cell_type": "code",
      "source": [
        "testY_iris"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iris-setosa</th>\n",
              "      <th>Iris-versicolor</th>\n",
              "      <th>Iris-virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
              "128            0                0               1\n",
              "11             1                0               0\n",
              "118            0                0               1\n",
              "15             1                0               0\n",
              "123            0                0               1\n",
              "135            0                0               1\n",
              "32             1                0               0\n",
              "1              1                0               0\n",
              "116            0                0               1\n",
              "45             1                0               0\n",
              "40             1                0               0\n",
              "115            0                0               1\n",
              "26             1                0               0\n",
              "28             1                0               0\n",
              "145            0                0               1\n",
              "97             0                1               0\n",
              "62             0                1               0\n",
              "77             0                1               0\n",
              "122            0                0               1\n",
              "112            0                0               1\n",
              "125            0                0               1\n",
              "31             1                0               0\n",
              "146            0                0               1\n",
              "29             1                0               0\n",
              "69             0                1               0\n",
              "149            0                0               1\n",
              "75             0                1               0\n",
              "20             1                0               0\n",
              "73             0                1               0\n",
              "120            0                0               1\n",
              "81             0                1               0\n",
              "99             0                1               0\n",
              "119            0                0               1\n",
              "12             1                0               0\n",
              "16             1                0               0\n",
              "51             0                1               0\n",
              "46             1                0               0\n",
              "89             0                1               0\n",
              "136            0                0               1\n",
              "114            0                0               1\n",
              "41             1                0               0\n",
              "90             0                1               0\n",
              "102            0                0               1\n",
              "109            0                0               1\n",
              "37             1                0               0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "6oR9Bdg4Zo_r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "Build the model with following layers: <br>\n",
        "1. First dense layer with 10 neurons with input shape 4 (according to the feature set) <br>\n",
        "2. Second Dense layer with 8 neurons <br>\n",
        "3. Output layer with 3 neurons with softmax activation (output layer, 3 neurons as we have 3 classes) <br>\n",
        "4. Use SGD and categorical_crossentropy loss "
      ]
    },
    {
      "metadata": {
        "id": "3E7Hk_o-Zo_t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize Sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "#Normalize input data\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=(4,)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iz19c7hC68TA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add First layer\n",
        "model.add(tf.keras.layers.Dense(10, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xh9XjdZs7vBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add secon layer\n",
        "model.add(tf.keras.layers.Dense(8, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qFvP1bf07405",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add output layer\n",
        "model.add(tf.keras.layers.Dense(3, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xGDcz2xt8lnP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create optimizer with non-default learning rate\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
        "\n",
        "#Compile the model\n",
        "model.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fZ1r1nA-Zo_w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Fitting the model and predicting "
      ]
    },
    {
      "metadata": {
        "id": "IkDTUIBRZo_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1431
        },
        "outputId": "9b2229c7-4fc5-4ef7-8c88-3b39606e1e60"
      },
      "cell_type": "code",
      "source": [
        "model.fit(trainX_iris,trainY_iris,          \n",
        "          validation_data=(testX_iris,testY_iris),\n",
        "          epochs=40,\n",
        "          batch_size=32)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 105 samples, validate on 45 samples\n",
            "Epoch 1/40\n",
            "105/105 [==============================] - 0s 232us/step - loss: 1.0000 - acc: 0.6857 - val_loss: 1.0078 - val_acc: 0.5778\n",
            "Epoch 2/40\n",
            "105/105 [==============================] - 0s 189us/step - loss: 0.9982 - acc: 0.6952 - val_loss: 1.0095 - val_acc: 0.5778\n",
            "Epoch 3/40\n",
            "105/105 [==============================] - 0s 193us/step - loss: 0.9982 - acc: 0.6190 - val_loss: 1.0069 - val_acc: 0.5778\n",
            "Epoch 4/40\n",
            "105/105 [==============================] - 0s 202us/step - loss: 0.9950 - acc: 0.6857 - val_loss: 1.0052 - val_acc: 0.5778\n",
            "Epoch 5/40\n",
            "105/105 [==============================] - 0s 193us/step - loss: 0.9911 - acc: 0.6857 - val_loss: 0.9997 - val_acc: 0.5778\n",
            "Epoch 6/40\n",
            "105/105 [==============================] - 0s 193us/step - loss: 0.9875 - acc: 0.6952 - val_loss: 0.9985 - val_acc: 0.5778\n",
            "Epoch 7/40\n",
            "105/105 [==============================] - 0s 189us/step - loss: 0.9864 - acc: 0.6571 - val_loss: 0.9950 - val_acc: 0.5778\n",
            "Epoch 8/40\n",
            "105/105 [==============================] - 0s 178us/step - loss: 0.9825 - acc: 0.6857 - val_loss: 0.9956 - val_acc: 0.5556\n",
            "Epoch 9/40\n",
            "105/105 [==============================] - 0s 192us/step - loss: 0.9794 - acc: 0.6857 - val_loss: 0.9918 - val_acc: 0.5778\n",
            "Epoch 10/40\n",
            "105/105 [==============================] - 0s 213us/step - loss: 0.9782 - acc: 0.6952 - val_loss: 0.9839 - val_acc: 0.5778\n",
            "Epoch 11/40\n",
            "105/105 [==============================] - 0s 200us/step - loss: 0.9772 - acc: 0.6762 - val_loss: 0.9755 - val_acc: 0.6000\n",
            "Epoch 12/40\n",
            "105/105 [==============================] - 0s 211us/step - loss: 0.9717 - acc: 0.6952 - val_loss: 0.9690 - val_acc: 0.6000\n",
            "Epoch 13/40\n",
            "105/105 [==============================] - 0s 227us/step - loss: 0.9694 - acc: 0.6952 - val_loss: 0.9633 - val_acc: 0.6444\n",
            "Epoch 14/40\n",
            "105/105 [==============================] - 0s 236us/step - loss: 0.9656 - acc: 0.6952 - val_loss: 0.9593 - val_acc: 0.6889\n",
            "Epoch 15/40\n",
            "105/105 [==============================] - 0s 191us/step - loss: 0.9637 - acc: 0.7143 - val_loss: 0.9541 - val_acc: 0.7333\n",
            "Epoch 16/40\n",
            "105/105 [==============================] - 0s 215us/step - loss: 0.9631 - acc: 0.7143 - val_loss: 0.9541 - val_acc: 0.6000\n",
            "Epoch 17/40\n",
            "105/105 [==============================] - 0s 210us/step - loss: 0.9584 - acc: 0.6857 - val_loss: 0.9550 - val_acc: 0.6000\n",
            "Epoch 18/40\n",
            "105/105 [==============================] - 0s 188us/step - loss: 0.9534 - acc: 0.6952 - val_loss: 0.9521 - val_acc: 0.6000\n",
            "Epoch 19/40\n",
            "105/105 [==============================] - 0s 183us/step - loss: 0.9536 - acc: 0.6857 - val_loss: 0.9462 - val_acc: 0.6000\n",
            "Epoch 20/40\n",
            "105/105 [==============================] - 0s 196us/step - loss: 0.9465 - acc: 0.6952 - val_loss: 0.9436 - val_acc: 0.6000\n",
            "Epoch 21/40\n",
            "105/105 [==============================] - 0s 192us/step - loss: 0.9441 - acc: 0.6952 - val_loss: 0.9391 - val_acc: 0.6000\n",
            "Epoch 22/40\n",
            "105/105 [==============================] - 0s 204us/step - loss: 0.9455 - acc: 0.6952 - val_loss: 0.9365 - val_acc: 0.6000\n",
            "Epoch 23/40\n",
            "105/105 [==============================] - 0s 248us/step - loss: 0.9391 - acc: 0.6952 - val_loss: 0.9320 - val_acc: 0.6000\n",
            "Epoch 24/40\n",
            "105/105 [==============================] - 0s 226us/step - loss: 0.9360 - acc: 0.6952 - val_loss: 0.9290 - val_acc: 0.6000\n",
            "Epoch 25/40\n",
            "105/105 [==============================] - 0s 194us/step - loss: 0.9320 - acc: 0.6952 - val_loss: 0.9217 - val_acc: 0.6000\n",
            "Epoch 26/40\n",
            "105/105 [==============================] - 0s 210us/step - loss: 0.9270 - acc: 0.6952 - val_loss: 0.9175 - val_acc: 0.6000\n",
            "Epoch 27/40\n",
            "105/105 [==============================] - 0s 191us/step - loss: 0.9221 - acc: 0.6952 - val_loss: 0.9129 - val_acc: 0.6000\n",
            "Epoch 28/40\n",
            "105/105 [==============================] - 0s 200us/step - loss: 0.9220 - acc: 0.6857 - val_loss: 0.9101 - val_acc: 0.6000\n",
            "Epoch 29/40\n",
            "105/105 [==============================] - 0s 196us/step - loss: 0.9159 - acc: 0.6952 - val_loss: 0.9073 - val_acc: 0.6000\n",
            "Epoch 30/40\n",
            "105/105 [==============================] - 0s 194us/step - loss: 0.9141 - acc: 0.6952 - val_loss: 0.9003 - val_acc: 0.6667\n",
            "Epoch 31/40\n",
            "105/105 [==============================] - 0s 198us/step - loss: 0.9128 - acc: 0.7048 - val_loss: 0.8937 - val_acc: 0.8444\n",
            "Epoch 32/40\n",
            "105/105 [==============================] - 0s 198us/step - loss: 0.9046 - acc: 0.7524 - val_loss: 0.8892 - val_acc: 0.8889\n",
            "Epoch 33/40\n",
            "105/105 [==============================] - 0s 203us/step - loss: 0.9038 - acc: 0.7810 - val_loss: 0.8836 - val_acc: 0.8889\n",
            "Epoch 34/40\n",
            "105/105 [==============================] - 0s 187us/step - loss: 0.8991 - acc: 0.8190 - val_loss: 0.8825 - val_acc: 0.8222\n",
            "Epoch 35/40\n",
            "105/105 [==============================] - 0s 196us/step - loss: 0.8988 - acc: 0.7143 - val_loss: 0.8800 - val_acc: 0.6667\n",
            "Epoch 36/40\n",
            "105/105 [==============================] - 0s 191us/step - loss: 0.8925 - acc: 0.7238 - val_loss: 0.8768 - val_acc: 0.6667\n",
            "Epoch 37/40\n",
            "105/105 [==============================] - 0s 196us/step - loss: 0.8952 - acc: 0.7143 - val_loss: 0.8681 - val_acc: 0.8889\n",
            "Epoch 38/40\n",
            "105/105 [==============================] - 0s 224us/step - loss: 0.8825 - acc: 0.8286 - val_loss: 0.8639 - val_acc: 0.8889\n",
            "Epoch 39/40\n",
            "105/105 [==============================] - 0s 228us/step - loss: 0.8844 - acc: 0.7619 - val_loss: 0.8624 - val_acc: 0.8222\n",
            "Epoch 40/40\n",
            "105/105 [==============================] - 0s 203us/step - loss: 0.8748 - acc: 0.7905 - val_loss: 0.8580 - val_acc: 0.8222\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4ddead7710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "OFjku34AZo_8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Report Accuracy of the predicted values"
      ]
    },
    {
      "metadata": {
        "id": "hLkeqOcHKxhV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6206fa39-e1e3-4f55-8b60-51612ce2d4e5"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(testX_iris,testY_iris)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45/45 [==============================] - 0s 180us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8579874171151055, 0.8222222248713176]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "DBtAoPO0M-zq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}